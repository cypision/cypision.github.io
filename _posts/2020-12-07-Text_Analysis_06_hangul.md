---
title:  "Sentiment Analysis using Korean"  
excerpt: "Text Analysis"  

categories:  
  - Deep-Learning  
tags:  
  - Text Analysis
  - í•œê¸€
  - ì›°ë‹ˆìŠ¤_ëŒ€í™”_ìŠ¤í¬ë¦½íŠ¸_ë°ì´í„°ì…‹.xlsx
last_modified_at: 2020-12-06 T16:13:00-05:00
---

## Reference  
* [AI Hub ì—ì„œ download](https://www.aihub.or.kr/)  
* ì›°ë‹ˆìŠ¤ ëŒ€í™” ìŠ¤í¬ë¦½íŠ¸ë¥¼ ê¸°ë³¸ì ìœ¼ë¡œ í™œìš©í•œë‹¤.

Word_Embedding_01,02 ì—ì„œ ì‚¬ìš©í–ˆë˜, Embedding vectorë¥¼ í™œìš©í•œë‹¤.  

#### google ë‚´ my drive ì—°ë™í•˜ê¸°


```python
# from google.colab import drive
# drive.mount('/content/gdrive')
```


```python
import numpy as np
import json
import random
import pandas as pd
```


```python
# í•™ìŠµ ì™„ë£Œëœ ì„ë² ë”© ì €ì¥í•˜ê¸° -> colab ë¶ˆëŸ¬ì˜¤ê¸°
# final_embeddings = cbow_model.get_weights()[0]
# final_embeddings = np.array(final_embeddings)
with open("D:/â˜…2020_ML_DL_Project/Alchemy/dataset/text_output/vecs.tsv") as f:
    vecs = [v.strip() for v in f.readlines()]
```


```python
## í•´ë‹¹ vecs ì— í•´ë‹¹í•˜ëŠ” ì›ë˜ ë‹¨ì–´ì‚¬ì „ (í˜•íƒœì†Œ í˜•íƒœë¡œ ë¶„í•´ëœ) ë¶ˆëŸ¬ì˜¤ê¸°.
with open("D:/â˜…2020_ML_DL_Project/Alchemy/dataset/text_output/meta.tsv") as m:
    meta = [v.strip() for v in m.readlines()]
```


```python
final_embeddings = [np.float32(v.split("\t")) for v in vecs]
```


```python
print(len(final_embeddings[0])) ## 2ì¤‘ list í˜•íƒœë¡œ ë¶ˆëŸ¬ì™”ë‹¤.
```

    128
    


```python
EXCEL_FILE_NALE = "D:/20_CNS_Text_Analysis/data_set/ì›°ë‹ˆìŠ¤_ëŒ€í™”_ìŠ¤í¬ë¦½íŠ¸_ë°ì´í„°ì…‹.xlsx"
data = pd.read_excel(EXCEL_FILE_NALE)
```


```python
data.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>êµ¬ë¶„</th>
      <th>ìœ ì €</th>
      <th>ì±—ë´‡</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>ê°ì •/ê°ì •ì¡°ì ˆì´ìƒ</td>
      <td>ì œ ê°ì •ì´ ì´ìƒí•´ì§„ ê²ƒ ê°™ì•„ìš”. ë‚¨í¸ë§Œ ë³´ë©´ í™”ê°€ ì¹˜ë°€ì–´ ì˜¤ë¥´ê³  ê°ì • ì¡°ì ˆì´ ì•ˆë˜ìš”.</td>
      <td>ê°ì •ì´ ì¡°ì ˆì´ ì•ˆ ë  ë•Œë§Œí¼ í˜ë“¤ ë•ŒëŠ” ì—†ëŠ” ê±° ê°™ì•„ìš”.</td>
    </tr>
    <tr>
      <th>1</th>
      <td>ê°ì •/ê°ì •ì¡°ì ˆì´ìƒ</td>
      <td>ë” ì´ìƒ ë‚´ ê°ì •ì„ ë‚´ê°€ ì»¨íŠ¸ë¡¤ ëª» í•˜ê² ì–´.</td>
      <td>ì €ë„ ê·¸ ê¸°ë¶„ ì´í•´í•´ìš”. ë§ì´ í˜ë“œì‹œì£ ?</td>
    </tr>
    <tr>
      <th>2</th>
      <td>ê°ì •/ê°ì •ì¡°ì ˆì´ìƒ</td>
      <td>í•˜ë£¨ì¢…ì¼ ì˜¤ë¥´ë½ë‚´ë¦¬ë½ ë¡¤ëŸ¬ì½”ìŠ¤í„° íƒ€ëŠ” ê¸°ë¶„ì´ì—ìš”.</td>
      <td>ê·¸ëŸ´ ë•ŒëŠ” ë°¥ì€ ì˜ ë¨¹ì—ˆëŠ”ì§€, ì ì€ ì˜ ì¤ëŠ”ì§€ ì²´í¬í•´ë³´ëŠ” ê²ƒë„ ì¢‹ì•„ìš”.</td>
    </tr>
    <tr>
      <th>3</th>
      <td>ê°ì •/ê°ì •ì¡°ì ˆì´ìƒ</td>
      <td>ê¼­ ë¡¤ëŸ¬ì½”ìŠ¤í„° íƒ€ëŠ” ê²ƒ ê°™ì•„ìš”.</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>4</th>
      <td>ê°ì •/ê°ì •ì¡°ì ˆì´ìƒ</td>
      <td>ë¡¤ëŸ¬ì½”ìŠ¤í„° íƒ€ëŠ” ê²ƒì²˜ëŸ¼ ê¸°ë¶„ì´ ì™”ë‹¤ ê°”ë‹¤ í•´ìš”.</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div>




```python
print(data.shape)
print(len(data['êµ¬ë¶„']))
```

    (5231, 3)
    5231
    


```python
data['êµ¬ë¶„'].value_counts()
```




    ì¦ìƒ/ë¶ˆë©´           209
    ëª¨í˜¸í•¨             180
    ê°ì •/í˜ë“¦           106
    ê°ì •/ìì‚´ì¶©ë™          94
    ê°ì •/ë¶€ì •ì ì‚¬ê³          93
                   ... 
    ì¦ìƒ/ì €ë¦¼í˜„ìƒ/ë°œ/ì†       5
    ë°°ê²½/ë‚¨í¸/ê´€ê³„ì†Œì›        5
    ë°°ê²½/ë¶€ëª¨/ê°€ì¶œ/ì•„ë²„ì§€      5
    ì¦ìƒ/ì²´ë ¥ì €í•˜           5
    ë°°ê²½/ë¶€ëª¨/ì–´ë¨¸ë‹ˆ/ì£½ìŒ      5
    Name: êµ¬ë¶„, Length: 359, dtype: int64



#### **í•„ìš”í•œ ë¶€ë¶„ë§Œ ë°œì·Œí•´ì„œ ë°ì´í„°í™” í•œë‹¤.**


```python
data['ì±—ë´‡'][3]
```




    nan




```python
## data['ì±—ë´‡'][3] nan ì´ê¸° ë•Œë¬¸ì— nan != nan ì´ ì„±ë¦½í•œë‹¤.
data['ì±—ë´‡'][3] != data['ì±—ë´‡'][3]
```




    True




```python
data['ì±—ë´‡'][0] != data['ì±—ë´‡'][0]
```




    False




```python
pd.isnull(data['ì±—ë´‡'][3])
```




    True




```python
## ì±—ë´‡ì»¬ëŸ¼ì´ ë¹ˆì¹¸ì¸ì§€ë¥¼ í™•ì¸í•˜ê¸° ìœ„í•œ ê°’. pd.isnull() í•´ë„ ë ë“¯
def isNaN(num):
    return num != num
```


```python
DATA = []
RESPONSE = {}
 
for i in range(len(data["êµ¬ë¶„"])):
    label = data["êµ¬ë¶„"][i]
    label_split = label.split("/")
    label_1 = "/".join(label_split[:2])
    sent = data["ìœ ì €"][i]
    if label_1 != "ëª¨í˜¸í•¨": 
        DATA.append(["Sent_{}".format(i), sent, label_1, label])
    if label_1 in RESPONSE:  ## ì´ë¯¸ RESPONSE dictì— keyë¡œ ìˆì„ ê²½ìš°
        if not pd.isnull(data["ì±—ë´‡"][i]): ## ì±—ë´‡ ì»¬ëŸ¼ ê°’ì´ NANì´ ì•„ë‹Œ ê²½ìš° 
            RESPONSE[label_1].append(data["ì±—ë´‡"][i]) ## keyê°€ ì¡´ì¬í•˜ëŠ” ìƒíƒœì—ì„œ ê¸°ì¡´ "ì±—ë´‡"ê°’ì— ìƒˆë¡œìš´ "ì±—ë´‡"ê°’ì„ appendí•œë‹¤.
    else: ## label_1 ì´ "ëª¨í˜¸í•¨"ì¸ ê²½ìš° or label_1 ì´ ì´ë¯¸ RESPONSE dictì— keyë¡œ ìˆì„ ê²½ìš°
        if not pd.isnull(data["ì±—ë´‡"][i]):  ## ì±—ë´‡ ì»¬ëŸ¼ ê°’ì´ NANì´ ì•„ë‹Œ ê²½ìš° 
            RESPONSE[label_1] = [data["ì±—ë´‡"][i]] ## value ë¥¼ ì¶”ê°€í•˜ëŠ”ë°, ìµœì´ˆ list í˜•ëŒ€ë¡œ ê°’ì„ ì§‘ì–´ë„£ëŠ”ë‹¤.
 
"""random shuffle & make them into train/test set"""
labels = [dat[2] for dat in DATA]
```


```python
print(len(DATA))
print(DATA[0])
print(labels[0],type(labels[0]))
```

    5051
    ['Sent_0', 'ì œ ê°ì •ì´ ì´ìƒí•´ì§„ ê²ƒ ê°™ì•„ìš”. ë‚¨í¸ë§Œ ë³´ë©´ í™”ê°€ ì¹˜ë°€ì–´ ì˜¤ë¥´ê³  ê°ì • ì¡°ì ˆì´ ì•ˆë˜ìš”.', 'ê°ì •/ê°ì •ì¡°ì ˆì´ìƒ', 'ê°ì •/ê°ì •ì¡°ì ˆì´ìƒ']
    ê°ì •/ê°ì •ì¡°ì ˆì´ìƒ <class 'str'>
    


```python
type(RESPONSE)
```




    dict




```python
RESPONSE['ì¦ìƒ/í”¼í•´ë§ìƒ']
```




    ['ê·¸ëŸ° ê¸°ë¶„ì´ ë“¤ ë•Œ ì •ë§ í˜ë“¤ì£ . ìƒê°ì„ ì¢€ ë‹¬ë¦¬ ê°€ì ¸ë³´ë©´ í¸í•˜ì§€ ì•Šì„ê¹Œìš”?',
     'ê·¸ ê¸°ë¶„ ë­”ì§€ ì•Œ ê²ƒ ê°™ì•„ìš”. ì¡°ê¸ˆì€ ë‹¤ë¥´ê²Œ ìƒê°ì„ í•´ë³´ëŠ” ê²ƒë„ ì¢‹ì„ ê²ƒ ê°™ì•„ìš”.',
     'ì •ë§ í˜ë“œì‹œê² ì–´ìš”. ì œê°€ ì˜†ì—ì„œ í˜ì´ ë˜ì–´ ë“œë¦´ê²Œìš”.',
     'ì •ë§ ìŠ¤íŠ¸ë ˆìŠ¤ ë°›ìœ¼ì‹œê² ì–´ìš”. ë‹¤ë¥¸ ë¶„ì—ê²Œ ë„ì›€ì„ ìš”ì²­í•´ë³´ëŠ” ê±´ ì–´ë–¨ê¹Œìš”?',
     'ëˆ„êµ°ê°€ ë‚˜ë¥¼ ì§€ì¼œë³´ê³  ìˆë‹¤ ìƒê°í•˜ë©´ ë„ˆë¬´ í˜ë“¤ê² ì–´ìš”. ì œê°€ ë„ì›€ì´ ë˜ê³  ì‹¶ë„¤ìš”.',
     'ê°ì‹œ ë‹¹í•˜ëŠ” ê²ƒë§Œí¼ ì‹ ê²½ì“°ì´ëŠ” ê²Œ ì—†ì£ . ì•„ì§ë„ ê·¸ ìƒí™©ì— ì²˜í•´ ê³„ì‹ ê°€ìš”?',
     'ê°ì‹œë¥¼ ë‹¹í•˜ì‹œëŠ” ê±´ê°€ìš”? ì •ë§ í˜ë“œì‹œê² ì–´ìš”.',
     'ì •ë§ ê³¤ë€í•˜ì‹œê² êµ°ìš”. í•œ ë²ˆ ëŒ€í™”ë¥¼ ë‚˜ëˆ  ë³´ëŠ” ê±´ ì–´ë–¨ê¹Œìš”?',
     'ì •ë„ê°€ ì‹¬í•˜ë©´ ê²½ì°°ì´ë‚˜ ë³‘ì›ì˜ ë„ì›€ì„ ë°›ì•„ë³´ëŠ” ê±´ ì–´ë– ì„¸ìš”?',
     'ì •ë§ í˜ë“  ìƒí™©ì´ì‹œêµ°ìš”. ì œê°€ ì‘ê²Œë‚˜ë§ˆ ìœ„ë¡œê°€ ë˜ê³  ì‹¶ì–´ìš”.',
     'ë§ì´ í˜ë“œì‹œê² ì–´ìš”. ê³ ë¯¼ì„ í„¸ì–´ ë†“ì„ ë°ê°€ í•„ìš”í•˜ì‹œë©´ ì œê°€ ë„ì™€ë“œë¦´ê²Œìš”.',
     'ê³ ë¯¼ì´ ë§ìœ¼ì…¨ê² ì–´ìš”. í™•ì‹ ì„ ìœ„í•´ ì¢€ ë” ìƒê°í•´ë³´ëŠ” ê±´ ì–´ë–¨ê¹Œìš”?',
     'ì •ë§ í˜ë“œì‹œê² ì–´ìš”. ì œê°€ í•­ìƒ ì˜†ì— ìˆì–´ ë“œë¦´ê²Œìš”. í˜ë‚´ì„¸ìš”.',
     'ê°ì‹œ ë‹¹í•˜ëŠ” ê²ƒë§Œí¼ ê´´ë¡œìš´ ê²Œ ì—†ì£ . ì œê°€ ë„ì›€ì´ ë˜ì–´ ë“œë¦¬ê³  ì‹¶ë„¤ìš”.',
     'ìƒí™œì´ ë¶ˆí¸í•˜ì‹œê² ì–´ìš”. ë‹¤ë¥¸ ì‚¬ëŒì˜ ë„ì›€ì„ ë°›ì•„ ë³´ëŠ” ê±´ ì–´ë–¨ê¹Œìš”?']



================================================================================================================================
#### ì›°ë‹ˆìŠ¤ ë°ì´í„° ê°ì„±ë¶„ì„ train, test ì…‹ìœ¼ë¡œ ë‚˜ëˆ„ê¸°  
ì´í›„, ê°ì •ë¶„ì„ label ê°¯ìˆ˜í™•ì¸


```python
print(len(DATA),DATA[0])
print(len(labels),labels[0])
```

    5051 ['Sent_0', 'ì œ ê°ì •ì´ ì´ìƒí•´ì§„ ê²ƒ ê°™ì•„ìš”. ë‚¨í¸ë§Œ ë³´ë©´ í™”ê°€ ì¹˜ë°€ì–´ ì˜¤ë¥´ê³  ê°ì • ì¡°ì ˆì´ ì•ˆë˜ìš”.', 'ê°ì •/ê°ì •ì¡°ì ˆì´ìƒ', 'ê°ì •/ê°ì •ì¡°ì ˆì´ìƒ']
    5051 ê°ì •/ê°ì •ì¡°ì ˆì´ìƒ
    


```python
from sklearn.model_selection import train_test_split
train, test = train_test_split(DATA, random_state = 2020, stratify = labels, test_size = 400)
```


```python
print("Data Example")
for i in range(5):
    print(train[i])
```

    Data Example
    ['Sent_4393', 'ë­”ê°€ í•˜ë£¨ì¢…ì¼ ì´ë ‡ê²Œ ë“¤ëœ¬ ê¸°ë¶„ì´ë‹¤ ë³´ë‹ˆê¹Œ ì ë„ ì˜ ì•ˆ ì™€.', 'ì¦ìƒ/ë¶ˆë©´', 'ì¦ìƒ/ë¶ˆë©´']
    ['Sent_603', 'ì•„ë¬´í•œí…Œë‚˜ í™”ë‚´ê³  ê·¸ëŸ¬ì§€ëŠ” ì•Šì•„.', 'ê°ì •/ë¶„ë…¸', 'ê°ì •/ë¶„ë…¸']
    ['Sent_4224', 'ì ìë¦¬ì— ëˆ„ì›Œë„ ë§¨ë‚  ë’¤ì²™ì´ê³ ... ì ì„ ì œëŒ€ë¡œ ì˜ ìˆ˜ ìˆì„ ë¦¬ê°€ ì—†ì§€.', 'ì¦ìƒ/ë¶ˆë©´', 'ì¦ìƒ/ë¶ˆë©´']
    ['Sent_3849', '5ì¼ ì „ì—ëŠ” ìƒˆë²½ì— ì¼ì–´ë‚˜ì„œ í™”ì¥ì‹¤ì„ ê°€ë‹¤ê°€ ìˆœê°„ì ìœ¼ë¡œ ì •ì‹ ì„ ìƒì—ˆì–´.', 'ì¦ìƒ/ê¸°ì ˆ', 'ì¦ìƒ/ê¸°ì ˆ']
    ['Sent_666', 'ê·¸ëƒ¥ ê°ì •ì´ì…ì´ ì‹¬í•˜ê²Œ ë˜ê³  ë¶ˆì•ˆê°ë„ ì˜ ëŠë¼ëŠ” ê²ƒ ê°™ì•„ìš”.', 'ê°ì •/ë¶ˆì•ˆê°', 'ê°ì •/ë¶ˆì•ˆê°']
    


```python
import collections

train_counter = collections.Counter()
```


```python
for dat in train:
    train_counter[dat[2]] += 1 ## dat[2] DATA ë‚´ì—ì„œ, 2 index ì˜ ì¦ìƒë¶€ë¶„ì„ keyë¡œ ì‚½ì…
print("ë¼ë²¨ ê°œìˆ˜:", len(train_counter), "\n") ## 176 ê°œ
print("*** LABEL ë¶„í¬ ***")

for cnt in train_counter.most_common():
    print("{} : {} ({:.2f}%)".format(cnt[0], cnt[1], 100*cnt[1]/len(train))) ## cnt[0]:key , cnt[1]:counting ê°¯ìˆ˜
```

    ë¼ë²¨ ê°œìˆ˜: 176 
    
    *** LABEL ë¶„í¬ ***
    ì¦ìƒ/ë¶ˆë©´ : 236 (5.07%)
    ë°°ê²½/ì§ì¥ : 152 (3.27%)
    ë°°ê²½/ë‚¨í¸ : 142 (3.05%)
    ê°ì •/ê±±ì • : 134 (2.88%)
    ë°°ê²½/ë¶€ëª¨ : 125 (2.69%)
    ê°ì •/í˜ë“¦ : 111 (2.39%)
    ë°°ê²½/ìƒí™œ : 107 (2.30%)
    ë°°ê²½/ì„±ê²© : 94 (2.02%)
    ê°ì •/ë¶ˆì•ˆê° : 91 (1.96%)
    ê°ì •/ìš°ìš¸ê° : 87 (1.87%)
    ê°ì •/ìì‚´ì¶©ë™ : 87 (1.87%)
    ì¦ìƒ/ë¬´ê¸°ë ¥ : 87 (1.87%)
    ê°ì •/ë¶€ì •ì ì‚¬ê³  : 86 (1.85%)
    ì¦ìƒ/í”¼í•´ë§ìƒ : 82 (1.76%)
    ì¦ìƒ/ì‹ìš•ì €í•˜ : 67 (1.44%)
    ë°°ê²½/ê±´ê°•ë¬¸ì œ : 65 (1.40%)
    ë°°ê²½/ë‚¨ìì¹œêµ¬ : 60 (1.29%)
    ì¦ìƒ/ë°˜ë³µí–‰ë™ : 59 (1.27%)
    ë°°ê²½/í•™êµ : 56 (1.20%)
    ë°°ê²½/ë¬¸ì œ : 55 (1.18%)
    ë°°ê²½/ìŒì£¼ : 53 (1.14%)
    ê°ì •/ë‹µë‹µ : 51 (1.10%)
    ë°°ê²½/ëŒ€í•™ : 48 (1.03%)
    ë°°ê²½/ì—°ì•  : 47 (1.01%)
    ê°ì •/ì§œì¦ : 46 (0.99%)
    ë°°ê²½/ê²½ì œì ë¬¸ì œ : 46 (0.99%)
    ë°°ê²½/ì‚¬ì—… : 45 (0.97%)
    ì¦ìƒ/ê¸°ì–µë ¥ì €í•˜ : 45 (0.97%)
    ì¦ìƒ/í˜¸í¡ê³¤ë€ : 44 (0.95%)
    ë°°ê²½/ì—¬ìì¹œêµ¬ : 41 (0.88%)
    ì¹˜ë£Œì´ë ¥/ë³‘ì›ë‚´ì› : 40 (0.86%)
    ì¦ìƒ/ë‘í†µ : 39 (0.84%)
    ì¦ìƒ/ë‘ê·¼ê±°ë¦¼ : 37 (0.80%)
    ë°°ê²½/ì¹œêµ¬ : 37 (0.80%)
    ë°°ê²½/ì–´ë¦°ì‹œì ˆ : 35 (0.75%)
    ê°ì •/í™” : 35 (0.75%)
    ì¦ìƒ/í™˜ì²­ : 34 (0.73%)
    ë°°ê²½/ëŒ€ì¸ê´€ê³„ : 33 (0.71%)
    ë¶€ê°€ì„¤ëª… : 33 (0.71%)
    ì¦ìƒ/ì€ë‘” : 32 (0.69%)
    ê°ì •/ì‹¬ë€ : 31 (0.67%)
    ì¦ìƒ/í†µì¦ : 31 (0.67%)
    ë°°ê²½/ì·¨ì—… : 30 (0.65%)
    ë°°ê²½/ê²°í˜¼ : 30 (0.65%)
    ë°°ê²½/ê°€ì¡± : 30 (0.65%)
    ê°ì •/í›„íšŒ : 30 (0.65%)
    ê°ì •/ëˆˆë¬¼ : 29 (0.62%)
    ë°°ê²½/ì‹œëŒ : 29 (0.62%)
    ë°°ê²½/ìë…€ : 29 (0.62%)
    ìê°€ì¹˜ë£Œ/ì‹¬ë¦¬ì¡°ì ˆ : 29 (0.62%)
    ê°ì •/ê´´ë¡œì›€ : 28 (0.60%)
    ì¦ìƒ/í­ì‹ : 28 (0.60%)
    ê°ì •/ìƒê° : 28 (0.60%)
    ê°ì •/ë¶„ë…¸ : 27 (0.58%)
    ì¦ìƒ/ì£½ìŒê³µí¬ : 27 (0.58%)
    ë°°ê²½/í•™ì—… : 26 (0.56%)
    ê°ì •/ìê´´ê° : 25 (0.54%)
    ì¦ìƒ/ì²´ì¤‘ê°ì†Œ : 25 (0.54%)
    ë°°ê²½/ì‚¬ê³  : 24 (0.52%)
    ì¦ìƒ/ì–´ì§€ëŸ¬ì›€ : 22 (0.47%)
    ê°ì •/ë¬´ì„œì›€ : 22 (0.47%)
    ì¦ìƒ/í”¼ë¡œ : 22 (0.47%)
    ì¦ìƒ/ëŒ€ì¸ê¸°í”¼ : 22 (0.47%)
    ê°ì •/ì™¸ë¡œì›€ : 21 (0.45%)
    ê°ì •/ìì¡´ê°ì €í•˜ : 21 (0.45%)
    ì¹˜ë£Œì´ë ¥/ê²€ì‚¬ : 21 (0.45%)
    ì¦ìƒ/ì§‘ì¤‘ë ¥ì €í•˜ : 21 (0.45%)
    ê°ì •/ì˜ìš•ìƒì‹¤ : 21 (0.45%)
    ê°ì •/ë¶ˆë§Œ : 21 (0.45%)
    ì¼ë°˜ëŒ€í™” : 19 (0.41%)
    ê°ì •/ê°ì •ì¡°ì ˆì´ìƒ : 19 (0.41%)
    ì¦ìƒ/ë°˜ë³µì‚¬ê³  : 19 (0.41%)
    ê°ì •/ì–µìš¸í•¨ : 19 (0.41%)
    ì¦ìƒ/ê³µí™©ë°œì‘ : 18 (0.39%)
    ê°ì •/ì„œìš´í•¨ : 18 (0.39%)
    ê°ì •/ì¶©ê²© : 18 (0.39%)
    ì¦ìƒ/ìí•´ : 18 (0.39%)
    ê°ì •/ëª¨í˜¸í•¨ : 18 (0.39%)
    ê°ì •/ë‘ë ¤ì›€ : 17 (0.37%)
    ê°ì •/ë¶ˆì¾Œê° : 17 (0.37%)
    ê°ì •/ì ˆë§ê° : 17 (0.37%)
    ê°ì •/ìŠ¬í”” : 17 (0.37%)
    ì¦ìƒ/ê°€ìŠ´ë‹µë‹µ : 17 (0.37%)
    ìƒíƒœ/ì¦ìƒì§€ì† : 16 (0.34%)
    ê°ì •/ì‹ ê²½ì“°ì„ : 16 (0.34%)
    ë°°ê²½/ì• ì™„ë™ë¬¼ : 16 (0.34%)
    ë°°ê²½/ì„ì‹  : 16 (0.34%)
    ì¦ìƒ/ì´ëª… : 15 (0.32%)
    ê°ì •/ìì‹ ê°ì €í•˜ : 15 (0.32%)
    ê°ì •/ê¸°ë¶„ì €í•˜ : 15 (0.32%)
    ê°ì •/ê³µí¬ : 15 (0.32%)
    ì¦ìƒ/ì•…ëª½ : 15 (0.32%)
    ì¦ìƒ/ìì‚´ì‹œë„ : 14 (0.30%)
    ì¦ìƒ/ê¸°ì–µìƒì‹¤ : 14 (0.30%)
    ê°ì •/ì†ìƒí•¨ : 14 (0.30%)
    ìƒíƒœ/ì–‘í˜¸ : 14 (0.30%)
    ê°ì •/ê¸´ì¥ : 14 (0.30%)
    ë‚´ì›ì´ìœ /ìƒë‹´ : 14 (0.30%)
    ê°ì •/ë¹„ê´€ì  : 14 (0.30%)
    ë°°ê²½/ìê° : 13 (0.28%)
    ì¦ìƒ/ê¸°ì ˆì˜ˆê¸° : 13 (0.28%)
    ì¦ìƒ/ì²´ì¤‘ì¦ê°€ : 13 (0.28%)
    ë°°ê²½/ì§„ë¡œ : 13 (0.28%)
    ì¦ìƒ/ê¸°ì ˆ : 12 (0.26%)
    ê°ì •/ì‚´ì¸ìš•êµ¬ : 12 (0.26%)
    ë°°ê²½/ê³µë¶€ : 12 (0.26%)
    ì¦ìƒ/ê°€ìŠ´ë–¨ë¦¼ : 12 (0.26%)
    ê°ì •/í—ˆë¬´í•¨ : 12 (0.26%)
    ê°ì •/ë©í•¨ : 12 (0.26%)
    ê°ì •/ì¦ê±°ì›€ : 11 (0.24%)
    ì¹˜ë£Œì´ë ¥/ì‘ê¸‰ì‹¤ : 11 (0.24%)
    ì¦ìƒ/í˜ë¹ ì§ : 11 (0.24%)
    ê°ì •/ì˜ê¸°ì†Œì¹¨ : 11 (0.24%)
    ê°ì •/ê³ ë…ê° : 11 (0.24%)
    ì¦ìƒ/ê³¼ìˆ˜ë©´ : 10 (0.22%)
    ë°°ê²½/ì´í˜¼ : 10 (0.22%)
    í˜„ì¬ìƒíƒœ/ì¦ìƒì•…í™” : 10 (0.22%)
    ê°ì •/ë¬´ë¯¸ê±´ì¡° : 10 (0.22%)
    ì¦ìƒ/ì•Œì½”ì˜¬ì˜ì¡´ : 10 (0.22%)
    ê°ì •/í†µì œë ¥ìƒì‹¤ : 9 (0.19%)
    ì¦ìƒ/í™˜ê° : 9 (0.19%)
    ë°°ê²½/ì´ì‚¬ : 9 (0.19%)
    ë°°ê²½/ì•„ë¥´ë°”ì´íŠ¸ : 9 (0.19%)
    ì¦ìƒ/ê±´ê°•ì—¼ë ¤ : 9 (0.19%)
    ì¦ìƒ/ì†Œí™”ë¶ˆëŸ‰ : 9 (0.19%)
    ê°ì •/ë¶ˆí¸ê° : 8 (0.17%)
    ê°ì •/ì¢Œì ˆ : 8 (0.17%)
    ê°ì •/ê³µí—ˆê° : 8 (0.17%)
    ê°ì •/ë‹¹í™© : 8 (0.17%)
    ì¦ìƒ/ì´ì¸ê° : 8 (0.17%)
    ê°ì •/ë¶ˆì‹  : 8 (0.17%)
    ì¦ìƒ/ì»¨ë””ì…˜ì €ì¡° : 8 (0.17%)
    ê°ì •/ë¯¸ì›€ : 8 (0.17%)
    ì¦ìƒ/ë§Œì„±í”¼ë¡œ : 8 (0.17%)
    ê°ì •/ë¯¸ì•ˆí•¨ : 8 (0.17%)
    ë°°ê²½/ìœ í•™ : 8 (0.17%)
    ê°ì •/ë¬´ë ¥ê° : 7 (0.15%)
    ì¦ìƒ/ìƒë¦¬ë¶ˆìˆœ : 7 (0.15%)
    ë°°ê²½/íƒ€ì¸ : 7 (0.15%)
    ë‚´ì›ì´ìœ /ì¹˜ë£Œ : 7 (0.15%)
    ì¦ìƒ/ê³¼ëŒ€ë§ìƒ : 7 (0.15%)
    ê°ì •/ì˜ˆë¯¼í•¨ : 7 (0.15%)
    ë°°ê²½/ìœ¡ì•„ : 7 (0.15%)
    ì¦ìƒ/ë©”ìŠ¤êº¼ì›€ : 7 (0.15%)
    ë‚´ì›ì´ìœ /ì˜ì‚¬ì†Œê²¬ : 7 (0.15%)
    ì¦ìƒ/í¸ë‘í†µ : 7 (0.15%)
    ë°°ê²½/ì „ì—°ì¸ : 6 (0.13%)
    ë°°ê²½/ì¢…êµ : 6 (0.13%)
    ê°ì •/ë°°ì‹ ê° : 6 (0.13%)
    ë°°ê²½/ê·€êµ­ : 6 (0.13%)
    ì¦ìƒ/ëŒ€í™”ê¸°í”¼ : 6 (0.13%)
    í˜„ì¬ìƒíƒœ/ì¦ìƒì§€ì† : 6 (0.13%)
    ì¦ìƒ/ì„±ìš•ìƒìŠ¹ : 6 (0.13%)
    ì¦ìƒ/ê°€ìŠ´í†µì¦ : 6 (0.13%)
    ì¦ìƒ/ì‹ ì²´ì´ìƒ : 6 (0.13%)
    í˜„ì¬ìƒíƒœ/ì¦ìƒê°ì†Œ : 6 (0.13%)
    ê°ì •/ê³¼ë¯¼ë°˜ì‘ : 6 (0.13%)
    ê°ì •/ì£„ì±…ê° : 6 (0.13%)
    ì¦ìƒ/ë°œì‘ : 6 (0.13%)
    ì¦ìƒ/ì¸ì§€ê¸°ëŠ¥ì €í•˜ : 6 (0.13%)
    ìƒíƒœ/ì¦ìƒê°ì†Œ : 6 (0.13%)
    ê°ì •/ì°½í”¼í•¨ : 6 (0.13%)
    ì¦ìƒ/ì†ì“°ë¦¼ : 6 (0.13%)
    ê°ì •/ì´ˆì¡°í•¨ : 6 (0.13%)
    ë°°ê²½/êµ°ëŒ€ : 5 (0.11%)
    ì¦ìƒ/ì²´ë ¥ì €í•˜ : 5 (0.11%)
    ì¦ìƒ/ê³µê²©ì ì„±í–¥ : 5 (0.11%)
    ì¦ìƒ/ì‹œë ¥ì €í•˜ : 5 (0.11%)
    ê°ì •/ê¸°ì‹œê° : 5 (0.11%)
    ìê°€ì¹˜ë£Œ/ìš´ë™ : 5 (0.11%)
    ìê°€ì¹˜ë£Œ/ì¶©ë¶„í•œíœ´ì‹ : 5 (0.11%)
    ì¦ìƒ/ì €ë¦¼í˜„ìƒ : 5 (0.11%)
    ì¦ìƒ/ì„±ê²©ë³€í™” : 5 (0.11%)
    ì¦ìƒ/ë–¨ë¦¼ : 5 (0.11%)
    ê°ì •/ê³¤í˜¹ê° : 5 (0.11%)
    ì›ì¸/ì—†ìŒ : 5 (0.11%)
    

ìµœì¢… 176ê°œì— í•´ë‹¹í•˜ëŠ” labelê°’ì„ ê°€ì§€ê³  ìˆìŒì„ ë³´ì˜€ë‹¤.
ë˜í•œ í•˜ìœ„ 1% ë¯¸ë§Œì˜ í•˜ìœ„ê°¯ìˆ˜ë¶„í¬ë¥¼ ë³´ì´ëŠ” label ê°¯ìˆ˜ë„ ìƒë‹¹í•˜ë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤.

## ê°ì„±ë¶„ì„ ëª¨ë¸ë§ í•˜ê¸°  

### step01. í•™ìŠµëŒ€ìƒì´ ë˜ëŠ” ì½˜í…ì¸ ì— ëŒ€í•˜ì—¬ ì •ìˆ˜ê°’ìœ¼ë¡œ ë²¡í„°í™” ì‹œí‚¨ë‹¤.  
__ì´ë•Œ, ê¸°ì¡´ meta ë‹¨ì–´(í† í°)ì—ì„œ ì—†ëŠ” ë¶€ë¶„ì„ í™•ì¥í•˜ì—¬ new_metaë¥¼ ë§Œë“¤ê³ __  
__ì´ë•Œ, ìƒˆë¡œ ebedding ê³„ì¸µë¶€í„° í•™ìŠµí•˜ì§€ ì•Šê³  ê¸°ì¡´ì— í™œìš©í–ˆë˜, ebedding ê°ì²´ë¥¼ ì†Œí™˜í•˜ì—¬ í™œìš©í•œë‹¤.__


```python
print(len(train),len(test))
train[11]
```

    4651 400
    




    ['Sent_1160', 'ì£½ëŠ” ê²Œ ë‚˜ì„ ê²ƒ ê°™ë‹¤ëŠ” ìƒê°ì´ ë“¤ì–´.', 'ê°ì •/ìì‚´ì¶©ë™', 'ê°ì •/ìì‚´ì¶©ë™']




```python
# í•™ìŠµ ì™„ë£Œëœ ì„ë² ë”© ì €ì¥í•˜ê¸° -> colab ë¶ˆëŸ¬ì˜¤ê¸°
with open("D:/â˜…2020_ML_DL_Project/Alchemy/dataset/text_output/vecs.tsv") as f:
    vecs = [v.strip() for v in f.readlines()]
```


```python
## í•´ë‹¹ vecs ì— í•´ë‹¹í•˜ëŠ” ì›ë˜ ë‹¨ì–´ì‚¬ì „ (í˜•íƒœì†Œ í˜•íƒœë¡œ ë¶„í•´ëœ) ë¶ˆëŸ¬ì˜¤ê¸°.
with open("D:/â˜…2020_ML_DL_Project/Alchemy/dataset/text_output/meta.tsv") as m:
    meta = [v.strip() for v in m.readlines()]
```


```python
final_embeddings = [np.float32(v.split("\t")) for v in vecs]
final_embeddings = np.array(final_embeddings)
final_embeddings.shape
```




    (70002, 128)



ê¸°ì¡´ embedding ë‹¨ì–´ì‚¬ì „ì—ì„œ í¬í•¨í•˜ì§€ ëª»í•˜ëŠ” ë‹¨ì–´ë“¤ì„ íŒŒì•…í•˜ì—¬ ì´ë“¤ì„ ì²˜ë¦¬í•´ì•¼ í•©ë‹ˆë‹¤.  
ê¸°ì¡´ë‹¨ì–´ì‚¬ì „ : meta  
ì‹ ê·œë‹¨ì–´ì‚¬ì „ : new_meta (ì´ ë¶€ë¶„ì€ colabì—ì„œ ìˆ˜í–‰ë¨)


```python
print(len(meta))
```

    70002
    

ë‹¨, ì—¬ê¸°ì„œ localë¡œ ì§„í–‰í•˜ê¸°ì—ëŠ” ë¬¸ì œê°€ ìƒê¹ë‹ˆë‹¤.(í•„ìì˜ localì—ëŠ” konlpê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•Šê³ , ê·¸ë™ì•ˆ Colabì—ì„œ ìˆ˜í–‰í•´ ì™”ìŒ)  

ê¸°ì¡´ meta ì—ì„œ ì»¤ë²„í•˜ì§€ ëª»í•˜ëŠ” ë‹¨ì–´(tokenizerëœ)ë“¤ì„ íŒŒì•…í•˜ê¸° ìœ„í•´ì„œëŠ”,  
1) konlpy - Komoran() ìœ¼ë¡œ ê¸°ì¡´ ë¬¸ì¥ì„ í•œêµ­ì–´ í† í°í™” ì‹œí‚¤ê³   
2) ê¸°ì¡´ meta íŒŒì¼ê³¼ ë¹„êµí•˜ì—¬ ì‹ ê·œ ë‹¨ì–´ë¥¼ íŒŒì•…  
3) ì‹ ê·œë‹¨ì–´ë“¤ë§Œí¼ ì¶”ê°€í•™ìŠµì„ í•˜ì—¬ embeddingë¥¼ ìƒˆë¡œ ë§Œë“¤ê±°ë‚˜ or ì‹ ê·œë‹¨ì–´ ë¶€ë¶„ë§Œ 0ì¸ ê°’ìœ¼ë¡œ embeddingì— ì¶”ê°€ ë°°ë¶„  

ìƒê¸° ê³¼ì •ì„ ê±°ì³ì•¼ í•©ë‹ˆë‹¤. í•˜ì§€ë§Œ, ì €ëŠ” ìƒê¸° ê³¼ì •ì„ colabì—ì„œ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤.  
[colab ìˆ˜í–‰ê³¼ì •](https://github.com/cypision/Alchemy-in-MLDL/blob/master/word_embedding_add_oob_Word.ipynb)  


```python
oov_counter = collections.Counter()
```

train,test ë°ì´í„°ë¥¼ meta ì •ë³´ì— ë§ì¶”ì–´ í† í°í™” -> ì •ìˆ˜ì¸ë±ì‹± í•œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¨ë‹¤.


```python
with open("D:/â˜…2020_ML_DL_Project/Alchemy/dataset/text_output/new_meta.tsv") as m:
    new_meta = [v.strip() for v in m.readlines()]
```


```python
train_ids = np.load('D:/â˜…2020_ML_DL_Project/Alchemy/dataset/text_output/Wellness_data_train_tokenized.npy')
train_labels = np.load('D:/â˜…2020_ML_DL_Project/Alchemy/dataset/text_output/Wellness_data_train_tokenized_label.npy')
test_ids = np.load('D:/â˜…2020_ML_DL_Project/Alchemy/dataset/text_output/Wellness_data_test_tokenized.npy')
test_labels = np.load('D:/â˜…2020_ML_DL_Project/Alchemy/dataset/text_output/Wellness_data_test_tokenized_label.npy')
```


```python
# Wellness_data_label_map.json
with open("D:/â˜…2020_ML_DL_Project/Alchemy/dataset/text_output/Wellness_data_label_map.json" , 'r') as f:
    label_map = json.loads(f.read())
```


```python
print(len(train),len(test))
train[11]
```

    4651 400
    




    ['Sent_1160', 'ì£½ëŠ” ê²Œ ë‚˜ì„ ê²ƒ ê°™ë‹¤ëŠ” ìƒê°ì´ ë“¤ì–´.', 'ê°ì •/ìì‚´ì¶©ë™', 'ê°ì •/ìì‚´ì¶©ë™']




```python
print(train_ids.shape,"\t test_ids.shape:",test_ids.shape)
print(train_ids[11])
```

    (4651, 50) 	 test_ids.shape: (400, 50)
    [330   6  40  75   7  35  82  77 180   3  23  26   4   0   0   0   0   0
       0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
       0   0   0   0   0   0   0   0   0   0   0   0   0   0]
    

train 4651 -> (4651,50)  
test   400 -> (400,50)  
ìœ¼ë¡œ ë³€ê²½ë˜ì—ˆë‹¤. ì´ ê³¼ì •ì€ colab ë§í¬ì£¼ì†Œë¥¼ í†µí•´ì„œ ë³´ë©´ ì¢€ë” í™•ì¸ê°€ëŠ¥í•©ë‹ˆë‹¤.[colab ìˆ˜í–‰ê³¼ì •](https://github.com/cypision/Alchemy-in-MLDL/blob/master/word_embedding_add_oob_Word.ipynb)  
ê°„ë‹¨íˆ ìš”ì•½í•˜ë©´,  
1) train,test ë‚´ì˜ setence ë°ì´í„°ë¥¼ tokenize(í•œê¸€)  
2) ê¸°ì¡´ meta(ë‹¨ì–´ì‚¬ì „)ì— ëŒ€ì…í•˜ì—¬ new_metaë¡œ í™•ì¥.(ê¸°ì¡´ meta ë‹¨ì–´ì¥ì— ì—†ëŠ” tokenì´ ìˆê¸° ë•Œë¬¸)  
3) new_metaì— ë”°ë¥¸ ì •ìˆ˜ ì¸ë±ìŠ¤ sentenceë¡œ ë³€ê²½í•˜ê³  padding ì„ ì¤˜ì„œ ê° ë¬¸ì¥ë³„ setence ê¸¸ì´ë¥¼ mat_len = 50 ê¸°ì¤€ìœ¼ë¡œ ë§ì¶¤  

### step02. ëª¨ë¸ì„ ì„¤ê³„í•˜ê³  Embedding layerë¥¼ ìˆ˜ì •í•œë‹¤.
__ì´ë•Œ, ìƒˆë¡œ ebedding ê³„ì¸µë¶€í„° í•™ìŠµí•˜ì§€ ì•Šê³  ê¸°ì¡´ì— í™œìš©í–ˆë˜, ebedding ê°ì²´ë¥¼ ì†Œí™˜í•˜ì—¬ í™œìš©í•œë‹¤.__


```python
import tensorflow as tf
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Embedding, LSTM, GRU, Dense, Dropout
```


```python
print(final_embeddings.shape)
print(type(label_map),len(label_map))

label_map_reverse = {}
for key,val in label_map.items():
    label_map_reverse[val] = key
```

    (70002, 128)
    <class 'dict'> 176
    


```python
vocab_size = len(new_meta) # ë‹¨ì–´ì‚¬ì „ ê°œìˆ˜
embedding_dim = final_embeddings.shape[1] # ì„ë² ë”© ì°¨ì›. ì—¬ê¸°ì„  128ì°¨ì›
rnn_hidden_dim = 300 # GRU hidden_size
final_dim = len(label_map) ## 176

""" MAKE MODEL """
model = Sequential(
    [Embedding(vocab_size, embedding_dim, mask_zero=True), ## mask_zero = tf.keras.preprocessing.sequence.pad_sequences ë¥¼ í†µí•´ input ê°’ë“¤ì˜ ê¸¸ì´ê°€ ì´ë¯¸ ê°™ìŒì„ ì•Œë¦¼
     GRU(rnn_hidden_dim), ## 
     Dense(rnn_hidden_dim, activation= "relu"),
     Dropout(0.3),
     Dense(final_dim, activation="softmax")] ## final_dim=176 ê°œì˜ ê°ì •ë¶„ì„ labelì— ëŒ€í•œ softmax ë¥¼ ì ìš©í•˜ì—¬ ë‹¤ì¤‘ í´ë˜ìŠ¤í”¼ì¼€ì´ì…˜ìœ¼ë¡œ ëª¨ë¸ì„ ì„¤ê³„í•œë‹¤.
)
```


```python
model.summary()
```

    Model: "sequential"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    embedding (Embedding)        (None, None, 128)         9020544   
    _________________________________________________________________
    gru (GRU)                    (None, 300)               387000    
    _________________________________________________________________
    dense (Dense)                (None, 300)               90300     
    _________________________________________________________________
    dropout (Dropout)            (None, 300)               0         
    _________________________________________________________________
    dense_1 (Dense)              (None, 176)               52976     
    =================================================================
    Total params: 9,550,820
    Trainable params: 9,550,820
    Non-trainable params: 0
    _________________________________________________________________
    


```python
for i in range(len(model.get_weights())):
    print("{}ë²ˆì§¸ ê°€ì¤‘ì¹˜ í–‰ë ¬ì˜ shape:{}".format(i, model.get_weights()[i].shape))
```

    0ë²ˆì§¸ ê°€ì¤‘ì¹˜ í–‰ë ¬ì˜ shape:(70473, 128)
    1ë²ˆì§¸ ê°€ì¤‘ì¹˜ í–‰ë ¬ì˜ shape:(128, 900)
    2ë²ˆì§¸ ê°€ì¤‘ì¹˜ í–‰ë ¬ì˜ shape:(300, 900)
    3ë²ˆì§¸ ê°€ì¤‘ì¹˜ í–‰ë ¬ì˜ shape:(2, 900)
    4ë²ˆì§¸ ê°€ì¤‘ì¹˜ í–‰ë ¬ì˜ shape:(300, 300)
    5ë²ˆì§¸ ê°€ì¤‘ì¹˜ í–‰ë ¬ì˜ shape:(300,)
    6ë²ˆì§¸ ê°€ì¤‘ì¹˜ í–‰ë ¬ì˜ shape:(300, 176)
    7ë²ˆì§¸ ê°€ì¤‘ì¹˜ í–‰ë ¬ì˜ shape:(176,)
    


```python
print(len(model.get_weights()))
print(model.get_weights()[0].shape)
```

    8
    (70473, 128)
    

ì•ì„œ ì–˜ê¸°í–ˆë‹¤ì‹œí”¼, ê¸°ì¡´ì— wiki ì‚¬ì „ìœ¼ë¡œ í•™ìŠµì‹œí‚¨, embedding(final_embeddings) ì„ ì¬í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  
<span style='color:red'>__ë‹¨ì–´ë¥¼ CBOWë‚˜ skip-gramìœ¼ë¡œ embedding ê°€ì¤‘ì¹˜í–‰ë ¬ì„ ë‹¤ì‹œ êµ¬í• ìˆ˜ë„ ìˆì§€ë§Œ, ë‹¨ì§€ í•™ìŠµë‹¨ê³„ì—ì„œ ì´ˆê¸°ê°’ìœ¼ë¡œë§Œ í™œìš©í•´ë„ íš¨ê³¼ê°€ ìˆë‹¤.__</span>  
ë‹¨ ì‚¬ìš©ì‹œì— ê¸°ì¡´ ë°°ì—´ê³¼ì˜ ì°¨ì›ìˆ˜ë¥¼ ì˜ ë§ì¶°ì¤˜ì•¼ í•©ë‹ˆë‹¤.  

ë³¸ ì˜ˆì—ì„œëŠ”  
Embedding(vocab_size, embedding_dim, mask_zero=True) ìœ¼ë¡œ ë³´ì—¬ì§€ë‹¤ì‹œí”¼, vocab_size(70473)ì´ ë“¤ì–´ê°”ìŠµë‹ˆë‹¤.  
ì´ëŠ” inputìœ¼ë¡œ ê°’ë“¤ì˜ í† í°ë‹¨ì–´ìˆ˜ì¤€ í¬ê°€ê°€ 70743ê°œë€ ëœ»ì…ë‹ˆë‹¤. í•˜ì§€ë§Œ ìš°ë¦¬ê°€ ê³¼ê±°ì— í•™ìŠµí•œ final_embeddings ë•Œì˜ í† í°ë‹¨ì–´ì‚¬ì „ ê°¯ìˆ˜ëŠ” 70002 ì˜€ìŠµë‹ˆë‹¤.  

ìœ„ì—ì„œ 0ë²ˆì§¸ ê°€ì¤‘ì¹˜ í–‰ë ¬ì˜ shape:(70473, 128) ì— ì´ˆê¸°ê°’ìœ¼ë¡œ final_embeddings(70002, 128)ë¥¼ ë„£ì–´ì£¼ë ¤ê³  í•˜ëŠ”ë° í–‰ì´ ë§ì§€ ì•Šìœ¼ë‹ˆ, ì´ë¥¼ 0ìœ¼ë¡œ ì±„ì›Œì„œ ìƒˆë¡­ê²Œ embedding í–‰ë ¬ì´ˆê¸°ê°’ì„ ë§Œë“¤ì–´ ë®ì–´ì¨ì¤ë‹ˆë‹¤. 


```python
print(vocab_size,final_embeddings.shape)
```

    70473 (70002, 128)
    


```python
## ë‹¨ì–´ì‚¬ì „ ê°œìˆ˜ ì²´í¬
org_vocab_size = final_embeddings.shape[0] ## 70002
new_vocab_size = len(new_meta)       ## 70473
 
print("CBOW initializeë  í† í° ê°œìˆ˜:", org_vocab_size)
print("ìƒˆë¡œìš´ ì„ë² ë”©ì˜ one-hot-vector:", new_vocab_size, "\n")
print("-> ëœë¤ ì´ˆê¸°í™”í•´ì•¼ í•  ë²¡í„° ì°¨ì›: {} x {}".format(new_vocab_size-org_vocab_size, embedding_dim))
```

    CBOW initializeë  í† í° ê°œìˆ˜: 70002
    ìƒˆë¡œìš´ ì„ë² ë”©ì˜ one-hot-vector: 70473 
    
    -> ëœë¤ ì´ˆê¸°í™”í•´ì•¼ í•  ë²¡í„° ì°¨ì›: 471 x 128
    


```python
rand_initial = np.random.uniform(-1,1,size=[vocab_size-org_vocab_size,embedding_dim])
rand_initial.shape
```




    (471, 128)




```python
initial_weight = np.append(final_embeddings, rand_initial, axis = 0)
initial_weight.shape
```




    (70473, 128)



model.weights[0] ë°”ê¿”ë¼ìš°ê¸°


```python
model.weights[0].assign(initial_weight) # model.weights[0] -> ì„ë² ë”© ë ˆì´ì–´ì— í•´ë‹¹
model.get_weights()[0]
```




    array([[ 3.65821011e-02,  2.09269263e-02,  4.37952392e-02, ...,
            -4.68397848e-02, -3.90023366e-02,  7.83827156e-03],
           [-1.08658604e-01,  1.20607175e-01,  2.56893903e-01, ...,
             2.73515940e-01, -1.67477235e-01,  1.85633793e-01],
           [-1.63065505e+00,  4.06452082e-02,  5.75998187e-01, ...,
            -7.51210332e-01, -2.29754075e-01,  3.93116146e-01],
           ...,
           [-4.35010314e-01, -3.36897731e-01,  2.59104937e-01, ...,
            -2.06732866e-03,  2.52970278e-01,  1.95310205e-01],
           [-9.23107386e-01,  8.29408407e-01,  9.49173152e-01, ...,
            -4.46789980e-01,  1.64622396e-01, -7.64461696e-01],
           [-7.53726959e-01, -7.91572854e-02, -1.17686565e-03, ...,
            -4.95805442e-02,  8.89336020e-02,  3.09113473e-01]], dtype=float32)



### step03. ëª¨ë¸ì„ compile ì´í›„ í•™ìŠµ


```python
## ëª¨ë¸ ì»´íŒŒì¼
model.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])
```

train set ì—ì„œ, validation setë¥¼ ë¶„ë¦¬í•´ë‚¸ë‹¤.


```python
from sklearn.model_selection import train_test_split
train_ids, val_ids, train_labels, val_labels = train_test_split(train_ids, train_labels , test_size=0.10, random_state=42, stratify=train_labels)
```


```python
## ëª¨ë¸ í•™ìŠµ
callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=1)

num_epochs = 100
history = model.fit(train_ids, train_labels, epochs=num_epochs, batch_size=200,validation_data=(val_ids, val_labels), callbacks=[callback])
```

    Train on 4185 samples, validate on 466 samples
    Epoch 1/100
    4185/4185 [==============================] - 2s 423us/sample - loss: 3.4095 - accuracy: 0.2461 - val_loss: 3.3772 - val_accuracy: 0.2489
    Epoch 2/100
    4185/4185 [==============================] - 1s 215us/sample - loss: 3.2400 - accuracy: 0.2631 - val_loss: 3.2990 - val_accuracy: 0.2575
    Epoch 3/100
    4185/4185 [==============================] - 1s 215us/sample - loss: 3.0403 - accuracy: 0.2984 - val_loss: 3.2013 - val_accuracy: 0.2811
    Epoch 4/100
    4185/4185 [==============================] - 1s 212us/sample - loss: 2.8790 - accuracy: 0.3245 - val_loss: 3.1715 - val_accuracy: 0.2768
    Epoch 5/100
    4185/4185 [==============================] - 1s 212us/sample - loss: 2.6902 - accuracy: 0.3639 - val_loss: 3.1705 - val_accuracy: 0.2983
    Epoch 6/100
    4185/4185 [==============================] - 1s 215us/sample - loss: 2.5241 - accuracy: 0.3845 - val_loss: 3.0713 - val_accuracy: 0.3004
    Epoch 7/100
    4185/4185 [==============================] - 1s 213us/sample - loss: 2.3434 - accuracy: 0.4146 - val_loss: 3.1096 - val_accuracy: 0.3069
    

### step04. test ë°ì´í„°ë¡œ ì„±ëŠ¥í‰ê°€í•˜ê¸°


```python
## sample
scores = model.predict(test_ids)
```


```python
scores.shape
```




    (400, 176)




```python
## 176 ì°¨ì›ìœ¼ë¡œ ê°’ì„ ë°›ì•˜ìœ¼ë‹ˆ, ì´ì¤‘ ê°€ì¥ í™•ë¥ ì ìœ¼ë¡œ ë†’ì€ ê°’ì„ returní•œ indexë¥¼ ì°¾ëŠ”ë‹¤.
print(scores[0].shape)
print(np.argmax(scores[0]))
```

    (176,)
    22
    

22 index ê°€ ê°€ì¥ ë†’ì€ í™•ë¥ ì„ ë³´ì˜€ë‹¤.


```python
print(scores[0][22])
print(label_map_reverse[test_labels[22]])
```

    0.08855945
    ì¦ìƒ/ë¶ˆë©´
    

ì´ë¥¼ í•¨ìˆ˜ë¡œ ë‚˜íƒ€ë‚´ë©´ í•˜ê¸°ì™€ ê°™ë‹¤.


```python
def make_prediction(test_ids):
    # model.predict í•¨ìˆ˜ë¥¼ í†µí•´ í™•ë¥ ê°’ ë°›ì•„ì˜¤ê¸°
    scores = model.predict(test_ids)
    # í™•ë¥ ê°’ì´ ê°€ì¥ ë†’ì€ ì¹´í…Œê³ ë¦¬ë¡œ ë¶„ë¥˜í•˜ê¸°
    predictions = np.argmax(scores, axis=1) ## index ê°’ì„ return í•œë‹¤.
    return scores , predictions 
```


```python
scores, predictions = make_prediction(test_ids)
```

ì´ë¥¼ í™•ì¸í•˜ëŠ” í•¨ìˆ˜ë¡œ êµ¬í˜„í•˜ë©´ í•˜ê¸°ì™€ ê°™ë‹¤.


```python
def SCORE(predictions, ground_truth):
    print("TEST SET ACCURACY: {:.2f}".format(sum(predictions == ground_truth) / len(predictions)))
    print("-"*80)
    label_reverse = {v:k for k, v in label_map.items()}
    for i in range(10):
        if predictions[i] != ground_truth[i]:
            print("ğŸ¥º: {}".format(test[i][1]))
            print("-> ğŸ‘©â€âš•ï¸: {} ğŸ¤–: {}".format( label_reverse[ground_truth[i]], label_reverse[predictions[i]]), "\n")   
```


```python
SCORE(predictions, test_labels)
```

    TEST SET ACCURACY: 0.24
    --------------------------------------------------------------------------------
    ğŸ¥º: ì €ëŠ” ì´ì œ ë§í–ˆì–´ìš”â€¦
    -> ğŸ‘©â€âš•ï¸: ê°ì •/ì¢Œì ˆ ğŸ¤–: ë°°ê²½/ë¶€ëª¨ 
    
    ğŸ¥º: ìŠ¤í…Œë¡œì´ë“œë¥¼ ë¨¹ìœ¼ë‹ˆê¹Œ ë¶ˆë©´ì´ ë” ì‹¬í•´ì§„ ê²ƒ ê°™ì•„.
    -> ğŸ‘©â€âš•ï¸: ì¦ìƒ/ë¶ˆë©´ ğŸ¤–: í˜„ì¬ìƒíƒœ/ì¦ìƒì•…í™” 
    
    ğŸ¥º: ë§›ìˆëŠ” ê±° ë¨¹ìœ¼ë©´ ê´œì°®ì•„ì¡ŒëŠ”ë°, ìš”ì¦˜ì€ ì•„ë‹ˆì—ìš”.
    -> ğŸ‘©â€âš•ï¸: ì¦ìƒ/ì‹ìš•ì €í•˜ ğŸ¤–: ë°°ê²½/ê±´ê°•ë¬¸ì œ 
    
    ğŸ¥º: ì´ìƒí•˜ê²Œ ì‚¬ê³ ë„ ìê¾¸ ìƒê¸°ëŠ” ê²ƒ ê°™ê³ â€¦
    -> ğŸ‘©â€âš•ï¸: ë°°ê²½/ì‚¬ê³  ğŸ¤–: ì¦ìƒ/ë¬´ê¸°ë ¥ 
    
    ğŸ¥º: ìˆ˜ìˆ  ëë‚˜ê³  í•­ì•” ì¹˜ë£Œ ì§„í–‰ ì¤‘ì´ì—ìš”.
    -> ğŸ‘©â€âš•ï¸: ë°°ê²½/ê±´ê°•ë¬¸ì œ ğŸ¤–: ë°°ê²½/ì§ì¥ 
    
    ğŸ¥º: ë‚˜ë„ ê·¼ì†ì„ ì¢€ í•´ë³´ê³  ì‹¶ë‹¤.
    -> ğŸ‘©â€âš•ï¸: ë°°ê²½/ì§ì¥ ğŸ¤–: ì¦ìƒ/í”¼í•´ë§ìƒ 
    
    ğŸ¥º: 2ë…„ì •ë„ ì§€ë‚˜ë‹ˆê¹Œ ë¹ˆí„¸í„°ë¦¬ê°€ ë˜ìˆì—ˆì–´ìš”.
    -> ğŸ‘©â€âš•ï¸: ë°°ê²½/ê²½ì œì ë¬¸ì œ ğŸ¤–: ë°°ê²½/ì–´ë¦°ì‹œì ˆ 
    
    ğŸ¥º: ê·¼ë° ì˜ì‚¬ê°€ ê·¸ ì™¸ì— ë˜ ë­ ì—†ëŠ”ì§€ ìì„¸í•˜ê²Œ ë§í•´ë‹¬ë¼ê³  í•˜ëŠ” ê±°ì•¼.
    -> ğŸ‘©â€âš•ï¸: ì¹˜ë£Œì´ë ¥/ë³‘ì›ë‚´ì› ğŸ¤–: ì¹˜ë£Œì´ë ¥/ê²€ì‚¬ 
    
    ğŸ¥º: ì•ˆì‹¬ì´ ì•ˆ ëœë‹¤â€¦
    -> ğŸ‘©â€âš•ï¸: ê°ì •/ë¶ˆì•ˆê° ğŸ¤–: ê°ì •/ê¸´ì¥ 
    
    

ì´ìƒìœ¼ë¡œ í¬ìŠ¤íŒ…ì„ ë§ˆì¹©ë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤.


```python

```
